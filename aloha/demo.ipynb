{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from lerobot.common.policies.factory import make_policy, _policy_cfg_from_hydra_cfg\n",
    "from pathlib import Path\n",
    "from lerobot.common.envs.factory import make_env\n",
    "from importlib import import_module\n",
    "from safetensors import safe_open\n",
    "from lerobot.scripts.eval import eval_policy\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def load_safetensors(path):\n",
    "    tensors = {}\n",
    "    with safe_open(path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "    return tensors\n",
    "\n",
    "device = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = 'insertion'\n",
    "task = 'transfer_cube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './configs/arp.yaml'\n",
    "ckpt_path = f'./weights/model.{task}.safetensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(config_path)\n",
    "cfg['dataset_repo_id'] = f'lerobot/aloha_sim_{task}_human'\n",
    "if task == 'insertion':\n",
    "    cfg.env.task = 'AlohaInsertion-v0'\n",
    "else:\n",
    "    cfg.env.task = 'AlohaTransferCube-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing policy module from: lerobot.common.policies.autoregressive_policy\n"
     ]
    }
   ],
   "source": [
    "prefix = 'lerobot.common.policies.' + cfg.policy['name']\n",
    "print(f'importing policy module from: {prefix}')\n",
    "config_mod = import_module(prefix + '.configuration')\n",
    "Config = config_mod.ARPConfig if hasattr(config_mod, 'ARPConfig') else config_mod.Config\n",
    "modeling_mod = import_module(prefix + '.modeling')\n",
    "Policy = modeling_mod.ARPPolicy if hasattr(modeling_mod, 'ARPPolicy') else modeling_mod.Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Hydra config is missing arguments: {'guide_chunk_size', 'action_chunk_size'}\n"
     ]
    }
   ],
   "source": [
    "config = _policy_cfg_from_hydra_cfg(Config, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = Policy(config)\n",
    "policy.load_state_dict(load_safetensors(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(cfg, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stepping through eval batches:  73%|███████▎  | 22/30 [35:39<12:58, 97.26s/it, running_success_rate=81.8%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episodes_rendered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideos_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./outputs/demo/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset_repo_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_progbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_inner_progbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/data/private/arp/aloha/lerobot/scripts/eval.py:285\u001b[0m, in \u001b[0;36meval_policy\u001b[0;34m(env, policy, n_episodes, max_episodes_rendered, videos_dir, return_episode_data, start_seed, enable_progbar, enable_inner_progbar)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    283\u001b[0m         start_seed \u001b[38;5;241m+\u001b[39m (batch_ix \u001b[38;5;241m*\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs), start_seed \u001b[38;5;241m+\u001b[39m ((batch_ix \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 285\u001b[0m rollout_data \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_episode_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrender_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_episodes_rendered\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_progbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_inner_progbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Figure out where in each rollout sequence the first done condition was encountered (results after\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# this won't be included).\u001b[39;00m\n\u001b[1;32m    296\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m rollout_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/data/private/arp/aloha/lerobot/scripts/eval.py:147\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(env, policy, seeds, return_observations, render_callback, enable_progbar)\u001b[0m\n\u001b[1;32m    139\u001b[0m progbar \u001b[38;5;241m=\u001b[39m trange(\n\u001b[1;32m    140\u001b[0m     max_steps,\n\u001b[1;32m    141\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning rollout with at most \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m steps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m enable_progbar,\n\u001b[1;32m    143\u001b[0m     leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(done):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Numpy array to tensor and changing dictionary keys to LeRobot policy format.\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_observations:\n\u001b[1;32m    149\u001b[0m         all_observations\u001b[38;5;241m.\u001b[39mappend(deepcopy(observation))\n",
      "File \u001b[0;32m/opt/data/private/arp/aloha/lerobot/common/envs/utils.py:51\u001b[0m, in \u001b[0;36mpreprocess_observation\u001b[0;34m(observations)\u001b[0m\n\u001b[1;32m     49\u001b[0m         img \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h w c -> b c h w\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     50\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 51\u001b[0m         img \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     53\u001b[0m         return_observations[imgkey] \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m observations:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_policy(env, policy, 30, max_episodes_rendered=30, videos_dir=Path('./outputs/demo/' + cfg['dataset_repo_id']), \n",
    "            enable_progbar=True, enable_inner_progbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
